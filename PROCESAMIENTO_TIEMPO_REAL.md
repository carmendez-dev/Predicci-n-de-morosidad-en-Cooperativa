# ‚ö° PROCESAMIENTO DE DATOS EN TIEMPO REAL
## Sistema de Predicci√≥n de Morosidad - Ahorro Valle

---

## üìã √çNDICE

1. [üéØ Introducci√≥n al Procesamiento en Tiempo Real](#-introducci√≥n-al-procesamiento-en-tiempo-real)
2. [üîÑ Flujo de Datos Completo](#-flujo-de-datos-completo)
3. [üìä Pipeline de Procesamiento](#-pipeline-de-procesamiento)
4. [üõ†Ô∏è Componentes del Sistema](#Ô∏è-componentes-del-sistema)
5. [‚ö° Optimizaciones de Performance](#-optimizaciones-de-performance)
6. [üìà Monitoreo en Tiempo Real](#-monitoreo-en-tiempo-real)
7. [üîß Configuraci√≥n Avanzada](#-configuraci√≥n-avanzada)
8. [üö® Manejo de Errores en Tiempo Real](#-manejo-de-errores-en-tiempo-real)
9. [üìä M√©tricas y KPIs](#-m√©tricas-y-kpis)

---

## üéØ INTRODUCCI√ìN AL PROCESAMIENTO EN TIEMPO REAL

### ¬øQu√© es el Procesamiento en Tiempo Real?

El **procesamiento en tiempo real** en nuestro sistema se refiere a la capacidad de:
- ‚úÖ **Recibir datos** del usuario instant√°neamente
- ‚úÖ **Validar y procesar** informaci√≥n en < 2 segundos
- ‚úÖ **Ejecutar predicciones** de ML inmediatamente
- ‚úÖ **Devolver resultados** al usuario sin demoras perceptibles
- ‚úÖ **Actualizar m√©tricas** autom√°ticamente

### Caracter√≠sticas del Sistema en Tiempo Real

```
ENTRADA ‚Üí VALIDACI√ìN ‚Üí PROCESAMIENTO ‚Üí PREDICCI√ìN ‚Üí RESPUESTA
   ‚Üì          ‚Üì             ‚Üì            ‚Üì           ‚Üì
 < 0.1s    < 0.2s        < 0.5s       < 1.0s     < 0.3s
   ‚îÇ          ‚îÇ             ‚îÇ            ‚îÇ           ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              TIEMPO TOTAL: < 2.0 segundos
```

### Ventajas del Procesamiento en Tiempo Real

#### üöÄ **Para el Usuario:**
- Respuesta inmediata a solicitudes
- Experiencia fluida e interactiva
- Feedback instant√°neo sobre errores
- Validaci√≥n en tiempo real de formularios

#### üìä **Para el Negocio:**
- Mayor throughput de evaluaciones
- Decisiones m√°s r√°pidas
- Mejor experiencia del cliente final
- Eficiencia operacional mejorada

#### üîß **Para el Sistema:**
- Uso eficiente de recursos
- Escalabilidad mejorada
- Monitoreo continuo
- Detecci√≥n temprana de problemas

---

## üîÑ FLUJO DE DATOS COMPLETO

### Arquitectura de Procesamiento

```
    USUARIO (Frontend)
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   NAVEGADOR WEB     ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Validaci√≥n JavaScript
‚îÇ                     ‚îÇ      Tiempo Real
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ HTTP POST /predecir
          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   SERVIDOR FLASK    ‚îÇ
‚îÇ                     ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Recepci√≥n Request
‚îÇ ‚îÇ  Request        ‚îÇ ‚îÇ      < 0.1s
‚îÇ ‚îÇ  Handler        ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ          ‚îÇ          ‚îÇ
‚îÇ          ‚ñº          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Validaci√≥n Backend
‚îÇ ‚îÇ  Validador      ‚îÇ ‚îÇ      < 0.2s
‚îÇ ‚îÇ  Backend        ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ          ‚îÇ          ‚îÇ
‚îÇ          ‚ñº          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Preprocesamiento
‚îÇ ‚îÇ  Data           ‚îÇ ‚îÇ      < 0.3s
‚îÇ ‚îÇ  Preprocessor   ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ          ‚îÇ          ‚îÇ
‚îÇ          ‚ñº          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Predicci√≥n ML
‚îÇ ‚îÇ  ML Engine      ‚îÇ ‚îÇ      < 1.0s
‚îÇ ‚îÇ  (Modelo)       ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ          ‚îÇ          ‚îÇ
‚îÇ          ‚ñº          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Post-procesamiento
‚îÇ ‚îÇ  Result         ‚îÇ ‚îÇ      < 0.2s
‚îÇ ‚îÇ  Processor      ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ          ‚îÇ          ‚îÇ
‚îÇ          ‚ñº          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Logging
‚îÇ ‚îÇ  Logger &       ‚îÇ ‚îÇ      < 0.1s
‚îÇ ‚îÇ  Metrics        ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ JSON Response
          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   NAVEGADOR WEB     ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ Render Resultado
‚îÇ   (Actualizaci√≥n)   ‚îÇ      < 0.1s
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚ñº
    USUARIO (Resultado)
```

### Flujo Temporal Detallado

```python
# Timestamps t√≠picos de una predicci√≥n
t0 = 0.000s    # Usuario env√≠a formulario
t1 = 0.050s    # Request llega al servidor
t2 = 0.150s    # Validaci√≥n completada
t3 = 0.400s    # Preprocesamiento terminado
t4 = 1.200s    # Predicci√≥n ML completada
t5 = 1.350s    # Post-procesamiento terminado
t6 = 1.400s    # Log guardado
t7 = 1.450s    # Response enviado
t8 = 1.500s    # Usuario ve resultado

TIEMPO TOTAL: 1.5 segundos (promedio)
```

---

## üìä PIPELINE DE PROCESAMIENTO

### 1. **Recepci√≥n de Datos (Frontend ‚Üí Backend)**

```javascript
// Frontend: Env√≠o de datos en tiempo real
function enviarPrediccion() {
    const timestamp_inicio = performance.now();
    
    // Validaci√≥n frontend inmediata
    const datosValidados = validarFormulario();
    if (!datosValidados.valido) {
        mostrarErrores(datosValidados.errores);
        return; // < 50ms
    }
    
    // Env√≠o AJAX as√≠ncrono
    fetch('/predecir', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'X-Request-ID': generarRequestID()
        },
        body: JSON.stringify({
            datos: datosFormulario,
            timestamp_cliente: timestamp_inicio,
            session_id: obtenerSessionID()
        })
    })
    .then(response => response.json())
    .then(resultado => {
        const tiempo_total = performance.now() - timestamp_inicio;
        mostrarResultado(resultado, tiempo_total);
    })
    .catch(error => manejarError(error));
}
```

### 2. **Procesamiento Backend en Tiempo Real**

```python
from flask import Flask, request, jsonify
import time
import threading
from queue import Queue
import logging

app = Flask(__name__)

# Cola para procesamiento as√≠ncrono
cola_predicciones = Queue(maxsize=100)
procesador_activo = True

class ProcesadorTiempoReal:
    def __init__(self):
        self.modelo = None
        self.preprocessor = None
        self.cache_modelo = {}
        self.metricas_tiempo_real = {
            'predicciones_por_minuto': 0,
            'tiempo_promedio_respuesta': 0,
            'errores_por_minuto': 0,
            'cache_hits': 0
        }
        self.inicializar_componentes()
        
    def inicializar_componentes(self):
        """Inicializaci√≥n optimizada de componentes"""
        start_time = time.time()
        
        # Cargar modelo una sola vez al iniciar
        self.modelo, self.preprocessor = self.cargar_modelo_optimizado()
        
        # Pre-calentar modelo con datos dummy
        self.precalentar_modelo()
        
        load_time = time.time() - start_time
        logging.info(f"Componentes inicializados en {load_time:.3f}s")
    
    def precalentar_modelo(self):
        """Pre-calienta el modelo para mejorar primera predicci√≥n"""
        datos_dummy = self.generar_datos_dummy()
        
        try:
            # Hacer predicci√≥n dummy para cargar modelo en memoria
            _ = self.procesar_prediccion_interna(datos_dummy)
            logging.info("Modelo pre-calentado exitosamente")
        except Exception as e:
            logging.warning(f"Error pre-calentando modelo: {e}")

@app.route('/predecir', methods=['POST'])
def predecir_tiempo_real():
    """Endpoint principal para predicciones en tiempo real"""
    
    # Timestamp de inicio
    timestamp_inicio = time.time()
    request_id = request.headers.get('X-Request-ID', 'unknown')
    
    try:
        # 1. RECEPCI√ìN Y VALIDACI√ìN R√ÅPIDA (< 0.1s)
        datos_raw = request.get_json()
        
        if not datos_raw:
            return jsonify({
                'error': 'No se recibieron datos',
                'codigo': 'E001',
                'tiempo_procesamiento': 0
            }), 400
        
        # 2. VALIDACI√ìN BACKEND (< 0.2s)
        resultado_validacion = validador.validar_datos_rapido(datos_raw['datos'])
        
        if not resultado_validacion['valido']:
            return jsonify({
                'error': 'Datos inv√°lidos',
                'errores': resultado_validacion['errores'],
                'codigo': 'E002',
                'tiempo_procesamiento': time.time() - timestamp_inicio
            }), 400
        
        # 3. PROCESAMIENTO EN TIEMPO REAL
        resultado = procesador.procesar_prediccion(
            datos=resultado_validacion['datos_procesados'],
            request_id=request_id,
            timestamp_inicio=timestamp_inicio
        )
        
        # 4. RESPUESTA R√ÅPIDA
        tiempo_total = time.time() - timestamp_inicio
        resultado['tiempo_procesamiento'] = tiempo_total
        resultado['request_id'] = request_id
        
        # Log as√≠ncrono para no bloquear respuesta
        threading.Thread(
            target=logger_asincrono,
            args=(resultado, tiempo_total, request_id)
        ).start()
        
        return jsonify(resultado)
        
    except Exception as e:
        tiempo_error = time.time() - timestamp_inicio
        logging.error(f"Error en predicci√≥n {request_id}: {e}")
        
        return jsonify({
            'error': 'Error interno del servidor',
            'codigo': 'E500',
            'tiempo_procesamiento': tiempo_error,
            'request_id': request_id
        }), 500

def logger_asincrono(resultado, tiempo_procesamiento, request_id):
    """Logger as√≠ncrono para no bloquear respuesta"""
    try:
        log_entry = {
            'timestamp': time.time(),
            'request_id': request_id,
            'resultado': resultado,
            'tiempo_procesamiento': tiempo_procesamiento,
            'memoria_usada': obtener_uso_memoria(),
            'cpu_usado': obtener_uso_cpu()
        }
        
        # Guardar en archivo
        guardar_log_prediccion(log_entry)
        
        # Actualizar m√©tricas en tiempo real
        actualizar_metricas_tiempo_real(tiempo_procesamiento)
        
    except Exception as e:
        logging.error(f"Error en logger as√≠ncrono: {e}")
```

### 3. **Preprocesamiento Optimizado**

```python
class PreprocessorTiempoReal:
    def __init__(self):
        self.transformadores_cargados = {}
        self.cache_transformaciones = {}
        self.estadisticas_cache = {'hits': 0, 'misses': 0}
        
    def procesar_datos_optimizado(self, datos):
        """Preprocesamiento optimizado para tiempo real"""
        timestamp_inicio = time.time()
        
        # 1. Crear clave de cache para datos similares
        cache_key = self.generar_cache_key(datos)
        
        # 2. Verificar cache primero
        if cache_key in self.cache_transformaciones:
            self.estadisticas_cache['hits'] += 1
            cached_result = self.cache_transformaciones[cache_key]
            
            logging.debug(f"Cache hit - Procesamiento en {time.time() - timestamp_inicio:.4f}s")
            return cached_result
        
        self.estadisticas_cache['misses'] += 1
        
        # 3. Procesamiento completo si no est√° en cache
        try:
            # Crear DataFrame optimizado
            df = self.crear_dataframe_optimizado(datos)
            
            # Aplicar transformaciones
            datos_procesados = self.aplicar_transformaciones_rapidas(df)
            
            # Guardar en cache (limitado a √∫ltimas 100 transformaciones)
            if len(self.cache_transformaciones) < 100:
                self.cache_transformaciones[cache_key] = datos_procesados
            
            tiempo_procesamiento = time.time() - timestamp_inicio
            logging.debug(f"Procesamiento completo en {tiempo_procesamiento:.4f}s")
            
            return datos_procesados
            
        except Exception as e:
            logging.error(f"Error en preprocesamiento: {e}")
            raise
    
    def crear_dataframe_optimizado(self, datos):
        """Crea DataFrame optimizado para velocidad"""
        # Pre-definir tipos de datos para evitar inferencia
        tipos_datos = {
            'edad': 'int32',
            'ingresos_mensuales': 'float32',
            'monto_credito': 'float32',
            'credito_score': 'int32'
            # ... otros campos
        }
        
        # Crear DataFrame con tipos espec√≠ficos
        df = pd.DataFrame([datos], dtype='object')
        
        # Convertir tipos eficientemente
        for columna, tipo in tipos_datos.items():
            if columna in df.columns:
                df[columna] = df[columna].astype(tipo)
        
        return df
    
    def aplicar_transformaciones_rapidas(self, df):
        """Aplica transformaciones optimizadas para velocidad"""
        
        # 1. Imputaci√≥n r√°pida (valores pre-calculados)
        df = self.imputar_valores_rapido(df)
        
        # 2. Escalado usando transformadores pre-cargados
        df_numerico = self.escalar_numericas_rapido(df)
        
        # 3. Encoding categ√≥ricas (mapping pre-definido)
        df_categorico = self.encode_categoricas_rapido(df)
        
        # 4. Combinar resultados
        resultado_final = np.hstack([df_numerico, df_categorico])
        
        return resultado_final
```

### 4. **Predicci√≥n ML Optimizada**

```python
class ModeloTiempoReal:
    def __init__(self):
        self.modelo_cargado = None
        self.cache_predicciones = {}
        self.estadisticas_modelo = {
            'predicciones_realizadas': 0,
            'cache_hits_modelo': 0,
            'tiempo_promedio_prediccion': 0
        }
        
    def predecir_optimizado(self, datos_procesados):
        """Predicci√≥n optimizada para tiempo real"""
        timestamp_inicio = time.time()
        
        try:
            # 1. Verificar cache de predicciones similares
            cache_key = hash(datos_procesados.tobytes())
            
            if cache_key in self.cache_predicciones:
                self.estadisticas_modelo['cache_hits_modelo'] += 1
                resultado_cache = self.cache_predicciones[cache_key]
                
                logging.debug("Cache hit en predicci√≥n ML")
                return resultado_cache
            
            # 2. Predicci√≥n real
            prediccion = self.modelo_cargado.predict(datos_procesados)
            probabilidades = self.modelo_cargado.predict_proba(datos_procesados)
            
            # 3. Procesar resultado
            resultado = {
                'prediccion': int(prediccion[0]),
                'probabilidades': probabilidades[0].tolist(),
                'confianza': float(np.max(probabilidades[0]))
            }
            
            # 4. Guardar en cache (√∫ltimas 50 predicciones)
            if len(self.cache_predicciones) < 50:
                self.cache_predicciones[cache_key] = resultado
            
            # 5. Actualizar estad√≠sticas
            tiempo_prediccion = time.time() - timestamp_inicio
            self.actualizar_estadisticas_modelo(tiempo_prediccion)
            
            return resultado
            
        except Exception as e:
            logging.error(f"Error en predicci√≥n ML: {e}")
            raise
    
    def actualizar_estadisticas_modelo(self, tiempo_prediccion):
        """Actualiza estad√≠sticas del modelo en tiempo real"""
        self.estadisticas_modelo['predicciones_realizadas'] += 1
        
        # Calcular promedio m√≥vil del tiempo de predicci√≥n
        n = self.estadisticas_modelo['predicciones_realizadas']
        promedio_anterior = self.estadisticas_modelo['tiempo_promedio_prediccion']
        
        nuevo_promedio = ((promedio_anterior * (n-1)) + tiempo_prediccion) / n
        self.estadisticas_modelo['tiempo_promedio_prediccion'] = nuevo_promedio
```

---

## üõ†Ô∏è COMPONENTES DEL SISTEMA

### Arquitectura de Componentes en Tiempo Real

```python
# Singleton para gesti√≥n centralizada
class SistemaTiempoReal:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(SistemaTiempoReal, cls).__new__(cls)
            cls._instance.inicializado = False
        return cls._instance
    
    def __init__(self):
        if not self.inicializado:
            self.inicializar_sistema()
            self.inicializado = True
    
    def inicializar_sistema(self):
        """Inicializaci√≥n optimizada del sistema completo"""
        
        # 1. Pool de Workers para procesamiento concurrente
        self.pool_workers = ThreadPoolExecutor(max_workers=4)
        
        # 2. Cache distribuido en memoria
        self.cache_sistema = {
            'modelos': {},
            'transformaciones': {},
            'predicciones': {},
            'estadisticas': {}
        }
        
        # 3. M√©tricas en tiempo real
        self.metricas_tiempo_real = MetricasTiempoReal()
        
        # 4. Monitor de sistema
        self.monitor_sistema = MonitorSistema()
        
        # 5. Queue para procesamiento as√≠ncrono
        self.cola_procesamiento = Queue(maxsize=1000)
        
        # 6. Iniciar workers background
        self.iniciar_workers_background()
    
    def iniciar_workers_background(self):
        """Inicia workers para procesamiento background"""
        
        # Worker para logging as√≠ncrono
        threading.Thread(
            target=self.worker_logging,
            daemon=True
        ).start()
        
        # Worker para actualizaci√≥n de m√©tricas
        threading.Thread(
            target=self.worker_metricas,
            daemon=True
        ).start()
        
        # Worker para limpieza de cache
        threading.Thread(
            target=self.worker_limpieza_cache,
            daemon=True
        ).start()
```

### Gesti√≥n de Memoria y Recursos

```python
class GestorRecursos:
    def __init__(self):
        self.limite_memoria = 1024 * 1024 * 1024  # 1GB
        self.limite_cache_entradas = 1000
        self.intervalo_limpieza = 300  # 5 minutos
        
    def monitorear_recursos(self):
        """Monitorea recursos del sistema continuamente"""
        import psutil
        
        while True:
            # Verificar uso de memoria
            memoria_actual = psutil.virtual_memory()
            
            if memoria_actual.percent > 85:
                self.limpiar_caches_agresivo()
                logging.warning(f"Memoria alta: {memoria_actual.percent}%")
            
            # Verificar uso de CPU
            cpu_actual = psutil.cpu_percent(interval=1)
            
            if cpu_actual > 80:
                self.reducir_workers_temporalmente()
                logging.warning(f"CPU alta: {cpu_actual}%")
            
            time.sleep(30)  # Verificar cada 30 segundos
    
    def limpiar_caches_agresivo(self):
        """Limpieza agresiva de caches cuando memoria es alta"""
        # Limpiar cache de predicciones m√°s antiguas
        self.limpiar_cache_por_timestamp()
        
        # Forzar garbage collection
        import gc
        gc.collect()
        
        logging.info("Limpieza agresiva de cache completada")
```

---

## ‚ö° OPTIMIZACIONES DE PERFORMANCE

### 1. **Caching Inteligente**

```python
class CacheInteligente:
    def __init__(self):
        self.cache_l1 = {}  # Cache m√°s r√°pido (en memoria)
        self.cache_l2 = {}  # Cache secundario
        self.estadisticas_cache = {
            'l1_hits': 0,
            'l2_hits': 0,
            'misses': 0,
            'total_requests': 0
        }
        
    def obtener_prediccion_cache(self, hash_datos):
        """Obtiene predicci√≥n del cache multinivel"""
        self.estadisticas_cache['total_requests'] += 1
        
        # Nivel 1 - Cache m√°s r√°pido
        if hash_datos in self.cache_l1:
            self.estadisticas_cache['l1_hits'] += 1
            return self.cache_l1[hash_datos]
        
        # Nivel 2 - Cache secundario
        if hash_datos in self.cache_l2:
            self.estadisticas_cache['l2_hits'] += 1
            # Promover a L1
            self.cache_l1[hash_datos] = self.cache_l2[hash_datos]
            return self.cache_l2[hash_datos]
        
        # Cache miss
        self.estadisticas_cache['misses'] += 1
        return None
    
    def guardar_en_cache(self, hash_datos, resultado):
        """Guarda resultado en cache multinivel"""
        # Siempre guardar en L1 primero
        self.cache_l1[hash_datos] = resultado
        
        # Gestionar tama√±o de cache L1
        if len(self.cache_l1) > 100:
            # Mover elementos m√°s antiguos a L2
            items_antiguos = list(self.cache_l1.items())[:50]
            for key, value in items_antiguos:
                self.cache_l2[key] = value
                del self.cache_l1[key]
        
        # Gestionar tama√±o de cache L2
        if len(self.cache_l2) > 500:
            # Eliminar m√°s antiguos
            items_eliminar = list(self.cache_l2.keys())[:200]
            for key in items_eliminar:
                del self.cache_l2[key]
```

### 2. **Pool de Conexiones y Workers**

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio

class PoolOptimizado:
    def __init__(self):
        # Pool principal para predicciones
        self.pool_predicciones = ThreadPoolExecutor(
            max_workers=4,
            thread_name_prefix="prediccion"
        )
        
        # Pool para tareas I/O (logging, etc.)
        self.pool_io = ThreadPoolExecutor(
            max_workers=2,
            thread_name_prefix="io"
        )
        
        # Sem√°foro para controlar concurrencia
        self.semaforo_predicciones = threading.Semaphore(4)
        
    def procesar_prediccion_async(self, datos):
        """Procesa predicci√≥n de forma as√≠ncrona"""
        future = self.pool_predicciones.submit(
            self.procesar_prediccion_worker,
            datos
        )
        return future
    
    def procesar_prediccion_worker(self, datos):
        """Worker optimizado para predicciones"""
        try:
            self.semaforo_predicciones.acquire()
            
            # Procesamiento real
            resultado = self.ejecutar_prediccion(datos)
            
            # Logging as√≠ncrono
            self.pool_io.submit(self.log_resultado_async, resultado)
            
            return resultado
            
        finally:
            self.semaforo_predicciones.release()
    
    def procesar_lote_predicciones(self, lote_datos):
        """Procesa m√∫ltiples predicciones en paralelo"""
        futures = []
        
        for datos in lote_datos:
            future = self.procesar_prediccion_async(datos)
            futures.append(future)
        
        # Recopilar resultados
        resultados = []
        for future in as_completed(futures, timeout=10):
            try:
                resultado = future.result()
                resultados.append(resultado)
            except Exception as e:
                logging.error(f"Error en predicci√≥n de lote: {e}")
                resultados.append(None)
        
        return resultados
```

### 3. **Optimizaci√≥n de Modelos ML**

```python
class ModeloOptimizado:
    def __init__(self):
        self.modelo_compilado = None
        self.feature_names_optimized = None
        self.preprocessing_pipeline_fast = None
        
    def optimizar_modelo_carga(self):
        """Optimiza modelo para carga r√°pida"""
        
        # 1. Cargar modelo una sola vez
        if self.modelo_compilado is None:
            # Cargar con optimizaciones espec√≠ficas
            self.modelo_compilado = self.cargar_modelo_con_optimizaciones()
            
        # 2. Pre-compilar pipeline de preprocessing
        self.preprocessing_pipeline_fast = self.crear_pipeline_rapido()
        
        # 3. Pre-calcular transformaciones comunes
        self.precalcular_transformaciones()
    
    def predecir_batch_optimizado(self, lote_datos):
        """Predicci√≥n optimizada para lotes"""
        
        # Procesamiento vectorizado
        datos_procesados = self.preprocessing_pipeline_fast.transform(lote_datos)
        
        # Predicci√≥n en lote (m√°s eficiente que individual)
        predicciones = self.modelo_compilado.predict(datos_procesados)
        probabilidades = self.modelo_compilado.predict_proba(datos_procesados)
        
        # Formatear resultados
        resultados = []
        for i, (pred, prob) in enumerate(zip(predicciones, probabilidades)):
            resultado = {
                'prediccion': int(pred),
                'probabilidades': prob.tolist(),
                'confianza': float(np.max(prob))
            }
            resultados.append(resultado)
        
        return resultados
```

---

## üìà MONITOREO EN TIEMPO REAL

### Dashboard de M√©tricas en Vivo

```python
class DashboardTiempoReal:
    def __init__(self):
        self.metricas_actuales = {}
        self.historial_metricas = []
        self.alertas_activas = []
        self.websocket_clients = set()
        
    def actualizar_metricas_tiempo_real(self):
        """Actualiza m√©tricas cada segundo"""
        while True:
            timestamp = time.time()
            
            # Recopilar m√©tricas del sistema
            metricas = {
                'timestamp': timestamp,
                'predicciones_por_segundo': self.calcular_pps(),
                'tiempo_respuesta_promedio': self.calcular_tiempo_promedio(),
                'uso_memoria': self.obtener_uso_memoria(),
                'uso_cpu': self.obtener_uso_cpu(),
                'cache_hit_rate': self.calcular_cache_hit_rate(),
                'errores_por_minuto': self.calcular_errores_por_minuto(),
                'conexiones_activas': len(self.websocket_clients)
            }
            
            # Actualizar m√©tricas actuales
            self.metricas_actuales = metricas
            
            # Agregar a historial (mantener √∫ltimas 1000)
            self.historial_metricas.append(metricas)
            if len(self.historial_metricas) > 1000:
                self.historial_metricas.pop(0)
            
            # Verificar alertas
            self.verificar_alertas(metricas)
            
            # Enviar a clientes WebSocket
            self.broadcast_metricas(metricas)
            
            time.sleep(1)  # Actualizar cada segundo
    
    def verificar_alertas(self, metricas):
        """Verifica condiciones de alerta"""
        alertas_nuevas = []
        
        # Alerta: Tiempo de respuesta alto
        if metricas['tiempo_respuesta_promedio'] > 3.0:
            alertas_nuevas.append({
                'tipo': 'warning',
                'mensaje': f"Tiempo de respuesta alto: {metricas['tiempo_respuesta_promedio']:.2f}s",
                'timestamp': time.time()
            })
        
        # Alerta: Uso de memoria alto
        if metricas['uso_memoria'] > 85:
            alertas_nuevas.append({
                'tipo': 'critical',
                'mensaje': f"Uso de memoria cr√≠tico: {metricas['uso_memoria']}%",
                'timestamp': time.time()
            })
        
        # Alerta: Cache hit rate bajo
        if metricas['cache_hit_rate'] < 0.3:
            alertas_nuevas.append({
                'tipo': 'info',
                'mensaje': f"Cache hit rate bajo: {metricas['cache_hit_rate']:.1%}",
                'timestamp': time.time()
            })
        
        # Agregar nuevas alertas
        self.alertas_activas.extend(alertas_nuevas)
        
        # Mantener solo √∫ltimas 50 alertas
        if len(self.alertas_activas) > 50:
            self.alertas_activas = self.alertas_activas[-50:]

@app.route('/api/metricas-tiempo-real')
def obtener_metricas_tiempo_real():
    """API para obtener m√©tricas en tiempo real"""
    dashboard = DashboardTiempoReal()
    
    return jsonify({
        'metricas_actuales': dashboard.metricas_actuales,
        'historial_ultimo_minuto': dashboard.historial_metricas[-60:],
        'alertas_activas': dashboard.alertas_activas[-10:],
        'estado_sistema': dashboard.evaluar_estado_sistema()
    })
```

### WebSocket para Actualizaciones en Vivo

```javascript
// Frontend: Conexi√≥n WebSocket para m√©tricas en tiempo real
class MonitorTiempoReal {
    constructor() {
        this.ws = null;
        this.charts = {};
        this.conectar();
    }
    
    conectar() {
        this.ws = new WebSocket('ws://127.0.0.1:5000/ws/metricas');
        
        this.ws.onopen = () => {
            console.log('Conectado al monitor de tiempo real');
            this.inicializarCharts();
        };
        
        this.ws.onmessage = (event) => {
            const metricas = JSON.parse(event.data);
            this.actualizarCharts(metricas);
            this.actualizarAlertas(metricas.alertas);
        };
        
        this.ws.onclose = () => {
            console.log('Desconectado del monitor');
            // Reconectar despu√©s de 5 segundos
            setTimeout(() => this.conectar(), 5000);
        };
        
        this.ws.onerror = (error) => {
            console.error('Error en WebSocket:', error);
        };
    }
    
    actualizarCharts(metricas) {
        // Actualizar gr√°fico de predicciones por segundo
        this.charts.pps.addPoint([
            metricas.timestamp * 1000,
            metricas.predicciones_por_segundo
        ], true, true);
        
        // Actualizar gr√°fico de tiempo de respuesta
        this.charts.tiempo_respuesta.addPoint([
            metricas.timestamp * 1000,
            metricas.tiempo_respuesta_promedio
        ], true, true);
        
        // Actualizar m√©tricas num√©ricas
        document.getElementById('uso-memoria').textContent = 
            metricas.uso_memoria + '%';
        document.getElementById('cache-hit-rate').textContent = 
            (metricas.cache_hit_rate * 100).toFixed(1) + '%';
    }
}

// Inicializar monitor al cargar la p√°gina
document.addEventListener('DOMContentLoaded', () => {
    const monitor = new MonitorTiempoReal();
});
```

---

## üîß CONFIGURACI√ìN AVANZADA

### Configuraci√≥n de Performance

```python
# config/tiempo_real.py
class ConfigTiempoReal:
    # Configuraci√≥n de Cache
    CACHE_L1_SIZE = 100
    CACHE_L2_SIZE = 500
    CACHE_TTL_SECONDS = 300
    
    # Configuraci√≥n de Workers
    MAX_WORKERS_PREDICCION = 4
    MAX_WORKERS_IO = 2
    QUEUE_SIZE = 1000
    
    # Configuraci√≥n de Timeouts
    TIMEOUT_PREDICCION = 5.0
    TIMEOUT_VALIDACION = 1.0
    TIMEOUT_LOGGING = 0.5
    
    # Configuraci√≥n de Monitoreo
    INTERVALO_METRICAS = 1.0
    HISTORIA_METRICAS = 1000
    MAX_ALERTAS = 50
    
    # Configuraci√≥n de Memoria
    LIMITE_MEMORIA_PERCENT = 85
    LIMITE_CPU_PERCENT = 80
    INTERVALO_LIMPIEZA = 300
    
    # Configuraci√≥n de Logs
    LOG_BUFFER_SIZE = 100
    LOG_FLUSH_INTERVAL = 10
    LOG_ROTATION_SIZE = '10MB'
    
    @classmethod
    def cargar_desde_archivo(cls, archivo_config):
        """Carga configuraci√≥n desde archivo JSON"""
        import json
        
        with open(archivo_config, 'r') as f:
            config_dict = json.load(f)
        
        for key, value in config_dict.items():
            if hasattr(cls, key.upper()):
                setattr(cls, key.upper(), value)
    
    @classmethod
    def optimizar_para_hardware(cls):
        """Optimiza configuraci√≥n seg√∫n hardware disponible"""
        import psutil
        
        # Ajustar workers seg√∫n CPUs disponibles
        cpu_count = psutil.cpu_count()
        cls.MAX_WORKERS_PREDICCION = min(cpu_count, 8)
        
        # Ajustar cache seg√∫n memoria disponible
        memoria_gb = psutil.virtual_memory().total / (1024**3)
        if memoria_gb >= 8:
            cls.CACHE_L1_SIZE = 200
            cls.CACHE_L2_SIZE = 1000
        elif memoria_gb >= 4:
            cls.CACHE_L1_SIZE = 100
            cls.CACHE_L2_SIZE = 500
        else:
            cls.CACHE_L1_SIZE = 50
            cls.CACHE_L2_SIZE = 200
```

### Variables de Entorno

```bash
# .env - Configuraci√≥n de producci√≥n
# Configuraci√≥n de Flask
FLASK_ENV=production
FLASK_DEBUG=False

# Configuraci√≥n de Workers
MAX_WORKERS=4
QUEUE_SIZE=1000

# Configuraci√≥n de Cache
ENABLE_CACHE=True
CACHE_SIZE_L1=100
CACHE_SIZE_L2=500

# Configuraci√≥n de Logging
LOG_LEVEL=INFO
LOG_ROTATION=True
LOG_SIZE_LIMIT=10MB

# Configuraci√≥n de Monitoreo
ENABLE_METRICS=True
METRICS_INTERVAL=1
WEBSOCKET_ENABLED=True

# Configuraci√≥n de Seguridad
RATE_LIMIT_ENABLED=True
RATE_LIMIT_PER_MINUTE=60
```

---

## üö® MANEJO DE ERRORES EN TIEMPO REAL

### Sistema de Recuperaci√≥n Autom√°tica

```python
class RecuperacionTiempoReal:
    def __init__(self):
        self.estado_sistema = "normal"
        self.intentos_recuperacion = {}
        self.max_intentos = 3
        
    def manejar_error_tiempo_real(self, error, contexto):
        """Maneja errores en tiempo real con recuperaci√≥n autom√°tica"""
        
        error_id = f"{type(error).__name__}_{hash(str(error))}"
        timestamp = time.time()
        
        # Registrar intento de recuperaci√≥n
        if error_id not in self.intentos_recuperacion:
            self.intentos_recuperacion[error_id] = {
                'count': 0,
                'first_occurrence': timestamp,
                'last_attempt': timestamp
            }
        
        intento = self.intentos_recuperacion[error_id]
        intento['count'] += 1
        intento['last_attempt'] = timestamp
        
        # Determinar estrategia de recuperaci√≥n
        if intento['count'] <= self.max_intentos:
            return self.ejecutar_recuperacion(error, contexto, intento['count'])
        else:
            return self.escalar_error(error, contexto)
    
    def ejecutar_recuperacion(self, error, contexto, intento_numero):
        """Ejecuta estrategia de recuperaci√≥n seg√∫n el intento"""
        
        estrategias = {
            1: self.recuperacion_rapida,
            2: self.recuperacion_media,
            3: self.recuperacion_completa
        }
        
        estrategia = estrategias.get(intento_numero, self.escalar_error)
        
        try:
            logging.warning(f"Ejecutando recuperaci√≥n nivel {intento_numero} para {type(error).__name__}")
            resultado = estrategia(error, contexto)
            
            if resultado:
                # Recuperaci√≥n exitosa
                error_id = f"{type(error).__name__}_{hash(str(error))}"
                del self.intentos_recuperacion[error_id]
                logging.info(f"Recuperaci√≥n exitosa en intento {intento_numero}")
            
            return resultado
            
        except Exception as e:
            logging.error(f"Error en recuperaci√≥n nivel {intento_numero}: {e}")
            return False
    
    def recuperacion_rapida(self, error, contexto):
        """Recuperaci√≥n r√°pida - reintentar operaci√≥n"""
        try:
            # Limpiar cache relevante
            self.limpiar_cache_relacionado(contexto)
            
            # Reintenta operaci√≥n con timeout reducido
            resultado = self.reintentar_operacion(contexto, timeout=1.0)
            return resultado
            
        except Exception:
            return False
    
    def recuperacion_media(self, error, contexto):
        """Recuperaci√≥n media - recargar componentes"""
        try:
            # Recargar modelo si es necesario
            if "modelo" in str(error).lower():
                self.recargar_modelo_rapido()
            
            # Limpiar todos los caches
            self.limpiar_todos_los_caches()
            
            # Reintentar con timeout normal
            resultado = self.reintentar_operacion(contexto, timeout=2.0)
            return resultado
            
        except Exception:
            return False
    
    def recuperacion_completa(self, error, contexto):
        """Recuperaci√≥n completa - reinicializar sistema"""
        try:
            # Reinicializar componentes cr√≠ticos
            self.reinicializar_componentes_criticos()
            
            # Reintentar operaci√≥n
            resultado = self.reintentar_operacion(contexto, timeout=5.0)
            return resultado
            
        except Exception:
            return False

# Decorador para manejo autom√°tico de errores
def con_recuperacion_automatica(func):
    """Decorador para funciones cr√≠ticas con recuperaci√≥n autom√°tica"""
    def wrapper(*args, **kwargs):
        recuperador = RecuperacionTiempoReal()
        
        try:
            return func(*args, **kwargs)
        except Exception as e:
            contexto = {
                'funcion': func.__name__,
                'args': args,
                'kwargs': kwargs,
                'timestamp': time.time()
            }
            
            # Intentar recuperaci√≥n autom√°tica
            if recuperador.manejar_error_tiempo_real(e, contexto):
                # Reintentar funci√≥n original
                return func(*args, **kwargs)
            else:
                # Si no se puede recuperar, propagar error
                raise
    
    return wrapper

# Uso del decorador
@con_recuperacion_automatica
def predecir_con_recuperacion(datos):
    """Funci√≥n de predicci√≥n con recuperaci√≥n autom√°tica"""
    return modelo.predict(datos)
```

---

## üìä M√âTRICAS Y KPIS

### KPIs de Tiempo Real

```python
class KPIsTiempoReal:
    def __init__(self):
        self.metricas = {
            # Performance
            'tiempo_respuesta_p50': 0,
            'tiempo_respuesta_p95': 0,
            'tiempo_respuesta_p99': 0,
            'throughput_predicciones_por_segundo': 0,
            
            # Calidad
            'tasa_exito': 0,
            'tasa_error': 0,
            'tasa_timeout': 0,
            'cache_hit_rate': 0,
            
            # Recursos
            'uso_cpu_promedio': 0,
            'uso_memoria_promedio': 0,
            'conexiones_concurrentes': 0,
            'queue_size_promedio': 0,
            
            # Business
            'predicciones_totales_dia': 0,
            'ratio_morosos_no_morosos': 0,
            'confianza_promedio_predicciones': 0
        }
        
        self.historial_tiempos = []
        self.ventana_tiempo = 300  # 5 minutos
        
    def registrar_prediccion(self, tiempo_respuesta, resultado, error=None):
        """Registra una predicci√≥n para calcular m√©tricas"""
        timestamp = time.time()
        
        # Agregar a historial
        self.historial_tiempos.append({
            'timestamp': timestamp,
            'tiempo_respuesta': tiempo_respuesta,
            'exitosa': error is None,
            'resultado': resultado
        })
        
        # Mantener solo √∫ltima ventana de tiempo
        tiempo_limite = timestamp - self.ventana_tiempo
        self.historial_tiempos = [
            record for record in self.historial_tiempos
            if record['timestamp'] > tiempo_limite
        ]
        
        # Recalcular m√©tricas
        self.calcular_metricas()
    
    def calcular_metricas(self):
        """Calcula todas las m√©tricas basadas en historial reciente"""
        if not self.historial_tiempos:
            return
        
        # Extraer tiempos de respuesta de predicciones exitosas
        tiempos_exitosos = [
            record['tiempo_respuesta'] 
            for record in self.historial_tiempos 
            if record['exitosa']
        ]
        
        if tiempos_exitosos:
            # Percentiles de tiempo de respuesta
            tiempos_ordenados = sorted(tiempos_exitosos)
            n = len(tiempos_ordenados)
            
            self.metricas['tiempo_respuesta_p50'] = tiempos_ordenados[int(n * 0.5)]
            self.metricas['tiempo_respuesta_p95'] = tiempos_ordenados[int(n * 0.95)]
            self.metricas['tiempo_respuesta_p99'] = tiempos_ordenados[int(n * 0.99)]
        
        # Tasas de √©xito/error
        total_predicciones = len(self.historial_tiempos)
        predicciones_exitosas = sum(1 for r in self.historial_tiempos if r['exitosa'])
        
        self.metricas['tasa_exito'] = predicciones_exitosas / total_predicciones
        self.metricas['tasa_error'] = 1 - self.metricas['tasa_exito']
        
        # Throughput
        tiempo_ventana = self.ventana_tiempo
        self.metricas['throughput_predicciones_por_segundo'] = total_predicciones / tiempo_ventana
        
        # M√©tricas de negocio
        resultados_validos = [r['resultado'] for r in self.historial_tiempos if r['exitosa'] and r['resultado']]
        
        if resultados_validos:
            morosos = sum(1 for r in resultados_validos if r.get('prediccion') == 1)
            no_morosos = sum(1 for r in resultados_validos if r.get('prediccion') == 0)
            
            if no_morosos > 0:
                self.metricas['ratio_morosos_no_morosos'] = morosos / no_morosos
            
            # Confianza promedio
            confianzas = [r.get('confianza', 0) for r in resultados_validos]
            if confianzas:
                self.metricas['confianza_promedio_predicciones'] = sum(confianzas) / len(confianzas)
    
    def generar_reporte_kpis(self):
        """Genera reporte completo de KPIs"""
        return {
            'timestamp': time.time(),
            'periodo_analisis_minutos': self.ventana_tiempo / 60,
            'total_predicciones_analizadas': len(self.historial_tiempos),
            'metricas': self.metricas,
            'estado_performance': self.evaluar_estado_performance(),
            'recomendaciones': self.generar_recomendaciones()
        }
    
    def evaluar_estado_performance(self):
        """Eval√∫a el estado general de performance"""
        problemas = []
        
        if self.metricas['tiempo_respuesta_p95'] > 3.0:
            problemas.append("Tiempo de respuesta P95 alto")
        
        if self.metricas['tasa_error'] > 0.05:
            problemas.append("Tasa de error alta")
        
        if self.metricas['throughput_predicciones_por_segundo'] < 1.0:
            problemas.append("Throughput bajo")
        
        if not problemas:
            return "EXCELENTE"
        elif len(problemas) == 1:
            return "BUENO"
        elif len(problemas) == 2:
            return "REGULAR"
        else:
            return "CRITICO"
```

### Dashboard de KPIs en Tiempo Real

```html
<!-- dashboard_tiempo_real.html -->
<div id="dashboard-tiempo-real" class="dashboard-container">
    <div class="metricas-principales">
        <div class="metrica-card">
            <h3>‚ö° Tiempo Respuesta</h3>
            <div class="metrica-valor" id="tiempo-p95">0.0s</div>
            <div class="metrica-detalle">P95</div>
        </div>
        
        <div class="metrica-card">
            <h3>üìä Throughput</h3>
            <div class="metrica-valor" id="throughput">0.0</div>
            <div class="metrica-detalle">pred/seg</div>
        </div>
        
        <div class="metrica-card">
            <h3>‚úÖ Tasa √âxito</h3>
            <div class="metrica-valor" id="tasa-exito">0.0%</div>
            <div class="metrica-detalle">√∫ltimos 5min</div>
        </div>
        
        <div class="metrica-card">
            <h3>üéØ Confianza</h3>
            <div class="metrica-valor" id="confianza-promedio">0.0%</div>
            <div class="metrica-detalle">promedio</div>
        </div>
    </div>
    
    <div class="graficos-tiempo-real">
        <div class="grafico-container">
            <canvas id="chart-tiempo-respuesta"></canvas>
        </div>
        
        <div class="grafico-container">
            <canvas id="chart-throughput"></canvas>
        </div>
    </div>
    
    <div class="alertas-tiempo-real" id="alertas-container">
        <!-- Alertas se insertan din√°micamente -->
    </div>
</div>

<script>
class DashboardTiempoReal {
    constructor() {
        this.charts = {};
        this.websocket = null;
        this.inicializar();
    }
    
    inicializar() {
        this.crearCharts();
        this.conectarWebSocket();
        this.iniciarActualizacionPeriodica();
    }
    
    crearCharts() {
        // Chart de tiempo de respuesta
        const ctx1 = document.getElementById('chart-tiempo-respuesta').getContext('2d');
        this.charts.tiempoRespuesta = new Chart(ctx1, {
            type: 'line',
            data: {
                labels: [],
                datasets: [{
                    label: 'Tiempo Respuesta (s)',
                    data: [],
                    borderColor: 'rgb(75, 192, 192)',
                    tension: 0.1
                }]
            },
            options: {
                responsive: true,
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 5
                    }
                },
                animation: false
            }
        });
        
        // Chart de throughput
        const ctx2 = document.getElementById('chart-throughput').getContext('2d');
        this.charts.throughput = new Chart(ctx2, {
            type: 'bar',
            data: {
                labels: [],
                datasets: [{
                    label: 'Predicciones/seg',
                    data: [],
                    backgroundColor: 'rgba(54, 162, 235, 0.2)',
                    borderColor: 'rgba(54, 162, 235, 1)',
                    borderWidth: 1
                }]
            },
            options: {
                responsive: true,
                scales: {
                    y: {
                        beginAtZero: true
                    }
                },
                animation: false
            }
        });
    }
    
    conectarWebSocket() {
        this.websocket = new WebSocket('ws://127.0.0.1:5000/ws/kpis');
        
        this.websocket.onmessage = (event) => {
            const kpis = JSON.parse(event.data);
            this.actualizarDashboard(kpis);
        };
        
        this.websocket.onclose = () => {
            setTimeout(() => this.conectarWebSocket(), 5000);
        };
    }
    
    actualizarDashboard(kpis) {
        // Actualizar m√©tricas principales
        document.getElementById('tiempo-p95').textContent = 
            kpis.metricas.tiempo_respuesta_p95.toFixed(2) + 's';
        document.getElementById('throughput').textContent = 
            kpis.metricas.throughput_predicciones_por_segundo.toFixed(1);
        document.getElementById('tasa-exito').textContent = 
            (kpis.metricas.tasa_exito * 100).toFixed(1) + '%';
        document.getElementById('confianza-promedio').textContent = 
            (kpis.metricas.confianza_promedio_predicciones * 100).toFixed(1) + '%';
        
        // Actualizar charts
        this.actualizarChart('tiempoRespuesta', 
            kpis.metricas.tiempo_respuesta_p95);
        this.actualizarChart('throughput', 
            kpis.metricas.throughput_predicciones_por_segundo);
        
        // Actualizar alertas si hay problemas
        if (kpis.estado_performance !== 'EXCELENTE') {
            this.mostrarAlerta(kpis.estado_performance, kpis.recomendaciones);
        }
    }
    
    actualizarChart(chartName, valor) {
        const chart = this.charts[chartName];
        const now = new Date().toLocaleTimeString();
        
        // Agregar nuevo punto
        chart.data.labels.push(now);
        chart.data.datasets[0].data.push(valor);
        
        // Mantener solo √∫ltimos 20 puntos
        if (chart.data.labels.length > 20) {
            chart.data.labels.shift();
            chart.data.datasets[0].data.shift();
        }
        
        chart.update();
    }
}

// Inicializar dashboard al cargar la p√°gina
document.addEventListener('DOMContentLoaded', () => {
    new DashboardTiempoReal();
});
</script>
```

---

**üìã Resumen del Procesamiento en Tiempo Real:**

‚úÖ **Arquitectura Optimizada**: Pipeline de < 2 segundos end-to-end
‚úÖ **Caching Inteligente**: Multinivel con alta tasa de hits
‚úÖ **Procesamiento Concurrente**: Workers optimizados para carga
‚úÖ **Monitoreo Continuo**: M√©tricas y KPIs en tiempo real
‚úÖ **Recuperaci√≥n Autom√°tica**: Manejo inteligente de errores
‚úÖ **Escalabilidad**: Configuraci√≥n adaptable al hardware
‚úÖ **Dashboard en Vivo**: Visualizaci√≥n de performance instant√°nea

*El sistema est√° dise√±ado para procesar miles de predicciones diarias manteniendo tiempos de respuesta consistentemente bajos y alta disponibilidad.*

**√öltima actualizaci√≥n:** 28 de Octubre, 2025